# Interactive Performances: Real-Time AI Systems Shaping Audience and Artist Experiences
In this git you will find all the source code for my Degree's Final Project related with the use of AI systems in live performances for enhancing artist and audience experience.

## Introduction
## Heatmaps
### Environment Set-up
Before creating the environment ensure that you have python installed in your device, this environment was created using python 3.8.10.

#### 1. Creation/activation of the environment
First, create a new `heat_env` environment and activate it before installing the dependencies 
```bash
python3.8 -m venv heat_env
```
#### 2. Dependencies installation 
Install all the dependencies defined in the `requirements.txt` file
```bash
pip install -r requirements.txt
```

### Dataset Set-up

The models are trained and tested using the **JHU-Crowd++** dataset from Kaggle. To proceed with the execution, first install teh complete dataset from the link and execute the pre-processing data file in data/heatmap_generation.py.
This is requiered since the dataset does not provide the heatmaps requiered for training and testing directly.

- **Direct link for download:** https://www.kaggle.com/datasets/hoangxuanviet/jhu-crowd/data  

This is requiered since the dataset does not provide the heatmaps directly.

### TouchDesigner Set-up
### Training
### Model Results
### Inference Results

## Music
### Environment Set-up
### Dataset Set-up
### TouchDesigner Set-up
### Training
### Model Results
### Inference Results
