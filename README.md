# Interactive Performances: Real-Time AI Systems Shaping Audience and Artist Experiences
In this git you will find all the source code for my Degree's Final Project related with the use of AI systems in live performances for enhancing artist and audience experience.

## Introduction
## Heatmaps
### Environment Set-up
Before creating the environment ensure that you have python installed in your device, this environment was created using python 3.8.10.

#### 1. Creation/activation of the environment
First, create a new `heat_env` environment and activate it before installing the dependencies 
```bash
python3.8 -m venv heat_env
```
#### 2. Dependencies installation 
Install all the dependencies defined in the `requirements.txt` file
```bash
pip install -r requirements.txt
```

### Dataset Set-up

The models are trained and tested using the **JHU-Crowd++** dataset from Kaggle. To proceed with the execution, first install the complete dataset from the link and execute the pre-processing data file in `heatmaps/data_preprocessing.py`.
This is necessary since the dataset does not provide the heatmaps required for training and testing directly.


- **Kaggle link for download:** https://www.kaggle.com/datasets/hoangxuanviet/jhu-crowd/data  

> **⚠️ Note:** Ensure that the paths in the `data_preprocessing.py` file are correct before executing.

### TouchDesigner Set-up
### Training
### Model Results
### Inference Results

## Music
### Environment Set-up
### Dataset Set-up
### TouchDesigner Set-up
### Training
### Model Results
### Inference Results
